# Digging-Deeper-Transformers-based-Models-for-Sentiment-Analysis
## ğŸ“Œ Project Overview
A comparative study to create the best model for predicting sentiment on the **UCI Sentiment Labelled Sentences** and **IMDB Reviews** datasets.

## ğŸ† Model Comparison
We benchmarked several architectures:
- **Traditional ML:** CNN, LSTM, Standard Transformer
- **BERT-based:** BERT, DeBERTa.
- **LLMs:** Gemma-3 (1B and 4B models), Llama 3.2 (1B).
Also doing analysis on each method on how to improved the performances.

## ğŸš€ Key Findings
- **The Winner:** Fine-tuning **Gemma 3 (4B)**, achieved accuracy of Up to **98%**, significantly beating traditional ML and BERT-based models.
- **Conclusion:** small LLM models that are fine-tuned beating traditional ML and BERT-based models.
